/**
 * AI Service - OpenClaw/Claude API é›†æˆ
 * æä¾›æµå¼å¯¹è¯å’Œéæµå¼å¯¹è¯èƒ½åŠ›
 */

import { AIRequest, AIResponse, StreamChunk, AgentConfig } from '../types/agent';
import { getAgentById } from '../agents/config';

// OpenClaw Gateway é…ç½®
const OPENCLAW_GATEWAY_URL = process.env.OPENCLAW_GATEWAY_URL || 'http://127.0.0.1:18789';
const OPENCLAW_API_KEY = process.env.OPENCLAW_API_KEY || '';

/**
 * æ„å»ºç³»ç»Ÿæç¤ºè¯
 */
export function buildSystemPrompt(agentId: string, context?: any): string {
  const agent = getAgentById(agentId);
  if (!agent) {
    throw new Error(`Agent not found: ${agentId}`);
  }

  let prompt = agent.systemPrompt;

  // æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
  if (context) {
    prompt += '\n\nã€å½“å‰ä¸Šä¸‹æ–‡ã€‘\n';
    
    if (context.siteId) {
      prompt += `- ç›‘æµ‹ç«™ç‚¹ID: ${context.siteId}\n`;
    }
    
    if (context.monitoringData) {
      prompt += `- ç›‘æµ‹æ•°æ®: ${JSON.stringify(context.monitoringData)}\n`;
    }
    
    if (context.alertInfo) {
      prompt += `- å‘Šè­¦ä¿¡æ¯: ${JSON.stringify(context.alertInfo)}\n`;
    }
    
    if (context.topic) {
      prompt += `- å½“å‰ä¸»é¢˜: ${context.topic}\n`;
    }
  }

  // æ·»åŠ èº«ä»½æ ‡è¯†
  prompt += `\n\nè¯·è®°ä½ï¼Œä½ æ˜¯${agent.name}ï¼ˆ${agent.title}ï¼‰ï¼Œç”¨ç¬¬ä¸€äººç§°å›å¤ã€‚`;

  return prompt;
}

/**
 * éæµå¼å¯¹è¯
 */
export async function chatCompletion(
  messages: Array<{ role: string; content: string }>,
  options: {
    model?: string;
    temperature?: number;
    maxTokens?: number;
  } = {}
): Promise<AIResponse> {
  const startTime = Date.now();

  // æ¨¡æ‹Ÿæ¨¡å¼ - å¦‚æœæ²¡æœ‰é…ç½®OpenClaw Gateway
  if (!OPENCLAW_GATEWAY_URL || OPENCLAW_GATEWAY_URL === 'http://127.0.0.1:18789') {
    // æ¨¡æ‹Ÿå»¶è¿Ÿ
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    const userMessage = messages[messages.length - 1]?.content || '';
    const systemPrompt = messages[0]?.content || '';
    
    // æ ¹æ®Agentç±»å‹ç”Ÿæˆä¸åŒçš„å›å¤
    let content = '';
    if (systemPrompt.includes('é‡‡æ ·ä¸“å®¶')) {
      content = `ä½œä¸ºé‡‡æ ·ä¸“å®¶ï¼Œé’ˆå¯¹æ‚¨çš„é—®é¢˜"${userMessage}"ï¼Œæˆ‘å»ºè®®ï¼š

1. **é‡‡æ ·ç‚¹ä½é€‰æ‹©**ï¼šå»ºè®®é€‰æ‹©é€šé£è‰¯å¥½çš„ä½ç½®ï¼Œè·ç¦»ç•œç¦½æ´»åŠ¨åŒºåŸŸ3-5ç±³
2. **é‡‡æ ·æ—¶é—´**ï¼šæœ€ä½³æ—¶é—´ä¸ºä¸Šåˆ9-11ç‚¹ï¼Œæ­¤æ—¶æ°”æº¶èƒ¶æµ“åº¦ç›¸å¯¹ç¨³å®š
3. **è®¾å¤‡å‚æ•°**ï¼šæ°”æº¶èƒ¶é‡‡æ ·å™¨æµé‡è®¾ç½®ä¸º200L/minï¼Œé‡‡æ ·æ—¶é—´30åˆ†é’Ÿ
4. **æ³¨æ„äº‹é¡¹**ï¼š
   - é‡‡æ ·å‰æ£€æŸ¥è®¾å¤‡å¯†å°æ€§
   - è®°å½•ç¯å¢ƒæ¸©æ¹¿åº¦æ•°æ®
   - é‡‡æ ·åç«‹å³å†·è—ä¿å­˜æ ·æœ¬

å¦‚éœ€æ›´è¯¦ç»†çš„é‡‡æ ·æ–¹æ¡ˆï¼Œè¯·æä¾›å…·ä½“çš„å…»æ®–åœºä¿¡æ¯ã€‚`;
    } else if (systemPrompt.includes('æ£€æµ‹åˆ†æå¸ˆ')) {
      content = `æ ¹æ®æ£€æµ‹åˆ†æï¼Œé’ˆå¯¹æ‚¨çš„é—®é¢˜"${userMessage}"ï¼Œæˆ‘çš„åˆ†æå¦‚ä¸‹ï¼š

**æ£€æµ‹æ•°æ®è§£è¯»**ï¼š
- å½“å‰æ ·æœ¬Ctå€¼ä¸º28.5ï¼Œå¤„äºé˜³æ€§ä¸´ç•ŒåŒºåŸŸ
- å»ºè®®è¿›è¡Œå¤æ£€ä»¥ç¡®è®¤ç»“æœ
- æ‰©å¢æ›²çº¿å‘ˆç°å…¸å‹çš„Så‹ç‰¹å¾

**è´¨é‡æ§åˆ¶**ï¼š
- é˜´æ€§å¯¹ç…§æ­£å¸¸ âœ“
- é˜³æ€§å¯¹ç…§æ­£å¸¸ âœ“
- å†…å‚åŸºå› è¡¨è¾¾ç¨³å®š

**åç»­å»ºè®®**ï¼š
1. é‡‡é›†æ›´å¤šæ ·æœ¬è¿›è¡ŒéªŒè¯
2. æ‰©å¤§ç›‘æµ‹èŒƒå›´è‡³å‘¨è¾¹åŒºåŸŸ
3. åŠ å¼ºç”Ÿç‰©å®‰å…¨é˜²æ§æªæ–½

é¢„è®¡24å°æ—¶å†…å¯å‡ºå…·æ­£å¼æ£€æµ‹æŠ¥å‘Šã€‚`;
    } else if (systemPrompt.includes('æƒ…æŠ¥ä¸“å‘˜')) {
      content = `æ ¹æ®æœ€æ–°æƒ…æŠ¥æ”¶é›†ï¼Œå…³äº"${userMessage}"ï¼š

**å…¨çƒç–«æƒ…åŠ¨æ€**ï¼ˆæˆªè‡³ä»Šæ—¥ï¼‰ï¼š
- ğŸ‡¨ğŸ‡³ å›½å†…ï¼šå†œä¸šå†œæ‘éƒ¨å‘å¸ƒæœ€æ–°ç›‘æµ‹æ•°æ®ï¼Œæ•´ä½“å¹³ç¨³
- ğŸ‡ºğŸ‡¸ ç¾å›½ï¼šå ªè¨æ–¯å·å‘ç°æ–°å‹å˜å¼‚æ ªï¼Œæ­£åœ¨å¯†åˆ‡ç›‘æµ‹
- ğŸ‡§ğŸ‡· å·´è¥¿ï¼šç¦½æµæ„Ÿé˜²æ§å–å¾—é˜¶æ®µæ€§æˆæ•ˆ

**æ”¿ç­–æ³•è§„**ï¼š
- ã€ŠåŠ¨ç‰©é˜²ç–«æ³•å®æ–½ç»†åˆ™ã€‹å·²äºæœ¬æœˆæ­£å¼å®æ–½
- æµ·å…³æ€»ç½²åŠ å¼ºè¿›å£ç•œç¦½äº§å“æ£€ç–«åŠ›åº¦

**ç ”ç©¶è¿›å±•**ï¼š
- ä¸­å›½å†œç§‘é™¢å›¢é˜Ÿåœ¨éæ´²çŒªç˜Ÿç–«è‹—ç ”ç©¶ä¸Šå–å¾—çªç ´
- æ–°å‹å¿«é€Ÿæ£€æµ‹è¯•å‰‚ç›’è¿›å…¥ä¸´åºŠè¯•éªŒé˜¶æ®µ

å»ºè®®æŒç»­å…³æ³¨WHOå’ŒOIEçš„æ¯å‘¨ç–«æƒ…é€šæŠ¥ã€‚`;
    } else {
      content = `æ„Ÿè°¢æ‚¨çš„é—®é¢˜"${userMessage}"ï¼

ä½œä¸ºåŒ—äº¬ç•œç‰§å…½åŒ»ç ”ç©¶æ‰€çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘å·²æ”¶åˆ°æ‚¨çš„è¯¢é—®å¹¶æ­£åœ¨è¿›è¡Œåˆ†æã€‚

**å½“å‰èƒ½åŠ›**ï¼š
- âœ… å®æ—¶ç›‘æµ‹æ•°æ®æŸ¥è¯¢
- âœ… å…¨çƒç–«æƒ…èµ„è®¯è¿½è¸ª
- âœ… ä¸“ä¸šæ£€æµ‹æŠ¥å‘Šè§£è¯»
- âœ… è¡Œä¸šç ”æŠ¥è‡ªåŠ¨ç”Ÿæˆ

**å»ºè®®**ï¼š
æ‚¨å¯ä»¥ç‚¹å‡»å³ä¾§çš„Agentå¡ç‰‡ï¼Œé€‰æ‹©ç‰¹å®šçš„ä¸“å®¶è¿›è¡Œå’¨è¯¢ï¼š
- ğŸ”¬ ä¸ä¸€ï¼ˆé‡‡æ ·ä¸“å®¶ï¼‰- æ°”æº¶èƒ¶é‡‡æ ·ç›¸å…³é—®é¢˜
- ğŸ§ª ä¸äºŒï¼ˆæ£€æµ‹åˆ†æå¸ˆï¼‰- æ£€æµ‹æ•°æ®åˆ†æ
- ğŸŒ ä¸ä¸‰ï¼ˆæƒ…æŠ¥ä¸“å‘˜ï¼‰- è¡Œä¸šèµ„è®¯å’Œæ”¿ç­–
- ğŸ“Š ä¸å››ï¼ˆç ”æŠ¥åŠ©æ‰‹ï¼‰- ç ”æŠ¥ç”Ÿæˆå’Œå†³ç­–å»ºè®®

è¯·é—®æœ‰ä»€ä¹ˆå…·ä½“çš„ç–«ç—…ç›‘æµ‹é—®é¢˜éœ€è¦å¸®åŠ©ï¼Ÿ`;
    }
    
    return {
      content,
      model: 'kimi-coding/k2p5',
      tokens: {
        prompt: messages.reduce((acc, m) => acc + m.content.length, 0),
        completion: content.length,
        total: messages.reduce((acc, m) => acc + m.content.length, 0) + content.length
      },
      latency: Date.now() - startTime
    };
  }

  try {
    const response = await fetch(`${OPENCLAW_GATEWAY_URL}/v1/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(OPENCLAW_API_KEY && { 'Authorization': `Bearer ${OPENCLAW_API_KEY}` })
      },
      body: JSON.stringify({
        model: options.model || 'anthropic/claude-sonnet-4-5-20250929',
        messages,
        temperature: options.temperature ?? 0.7,
        max_tokens: options.maxTokens ?? 2048,
        stream: false
      })
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`AI request failed: ${response.status} - ${error}`);
    }

    const data = await response.json();
    const latency = Date.now() - startTime;

    return {
      content: data.choices[0].message.content,
      model: data.model || 'unknown',
      tokens: {
        prompt: data.usage?.prompt_tokens || 0,
        completion: data.usage?.completion_tokens || 0,
        total: data.usage?.total_tokens || 0
      },
      latency
    };
  } catch (error) {
    console.error('AI chat completion error:', error);
    throw error;
  }
}

/**
 * æµå¼å¯¹è¯
 */
export async function* streamCompletion(
  messages: Array<{ role: string; content: string }>,
  options: {
    model?: string;
    temperature?: number;
    maxTokens?: number;
  } = {}
): AsyncGenerator<StreamChunk> {
  try {
    const response = await fetch(`${OPENCLAW_GATEWAY_URL}/v1/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(OPENCLAW_API_KEY && { 'Authorization': `Bearer ${OPENCLAW_API_KEY}` })
      },
      body: JSON.stringify({
        model: options.model || 'anthropic/claude-sonnet-4-5-20250929',
        messages,
        temperature: options.temperature ?? 0.7,
        max_tokens: options.maxTokens ?? 2048,
        stream: true
      })
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`AI stream request failed: ${response.status} - ${error}`);
    }

    const reader = response.body?.getReader();
    if (!reader) {
      throw new Error('No response body');
    }

    const decoder = new TextDecoder();
    let buffer = '';

    while (true) {
      const { done, value } = await reader.read();
      
      if (done) {
        yield { content: '', done: true };
        break;
      }

      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split('\n');
      buffer = lines.pop() || '';

      for (const line of lines) {
        if (line.trim() === '' || line.startsWith(':')) continue;
        
        if (line.startsWith('data: ')) {
          const data = line.slice(6);
          
          if (data === '[DONE]') {
            yield { content: '', done: true };
            return;
          }

          try {
            const chunk = JSON.parse(data);
            const content = chunk.choices?.[0]?.delta?.content || '';
            
            if (content) {
              yield {
                content,
                done: false,
                metadata: {
                  model: chunk.model
                }
              };
            }
          } catch (e) {
            // å¿½ç•¥è§£æé”™è¯¯
          }
        }
      }
    }
  } catch (error) {
    console.error('AI stream completion error:', error);
    throw error;
  }
}

/**
 * Agent å¯¹è¯åŒ…è£…å™¨
 */
export async function chatWithAgent(
  agentId: string,
  userMessage: string,
  history: Array<{ role: string; content: string }> = [],
  context?: any
): Promise<AIResponse> {
  const systemPrompt = buildSystemPrompt(agentId, context);
  
  const messages = [
    { role: 'system', content: systemPrompt },
    ...history,
    { role: 'user', content: userMessage }
  ];

  return chatCompletion(messages);
}

/**
 * Agent æµå¼å¯¹è¯åŒ…è£…å™¨
 */
export async function* streamWithAgent(
  agentId: string,
  userMessage: string,
  history: Array<{ role: string; content: string }> = [],
  context?: any
): AsyncGenerator<StreamChunk> {
  const systemPrompt = buildSystemPrompt(agentId, context);
  
  const messages = [
    { role: 'system', content: systemPrompt },
    ...history,
    { role: 'user', content: userMessage }
  ];

  yield* streamCompletion(messages);
}
